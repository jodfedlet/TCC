{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jodfedlet/TCC/blob/main/TCCII/Twitter/LDA_with_gensim_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGH1shqALApT"
      },
      "source": [
        "#Objetivos\n",
        " - Dividir o df por mês\n",
        " - Para cada subdf, realizar a experimentação:\n",
        "    - definir numeros de tópicos\n",
        "    - criar o modelo LDA\n",
        "        - passar o número de tópico a cada vez\n",
        "        - definir o valor de alfa e beta\n",
        "    - Aplicar o modelo LDA para cada número de tópicos\n",
        "    - Encontrar o número de tópicos que melhor representa os documentos (fase que pode ser realizada à partir de conhecimentos empíricos dos documentos ou por métrica de coerência)\n",
        " - Salvar o melhor número de tópicos para cada subdf   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVyhbHeD61t9",
        "outputId": "f3c56d53-0f1e-4706-c58d-a03f39e0c603"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 56.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (6.0.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyldavis\n",
            "  Downloading pyLDAvis-3.3.1.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 7.1 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pyldavis) (1.3.5)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyldavis) (2.8.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyldavis) (0.16.0)\n",
            "Collecting funcy\n",
            "  Downloading funcy-1.17-py2.py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyldavis) (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyldavis) (1.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyldavis) (2.11.3)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from pyldavis) (1.21.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyldavis) (1.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyldavis) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyldavis) (57.4.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyldavis) (4.2.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyldavis) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyldavis) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyldavis) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyldavis) (6.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyldavis) (2.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from numexpr->pyldavis) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->numexpr->pyldavis) (3.0.9)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyldavis) (3.1.0)\n",
            "Building wheels for collected packages: pyldavis\n",
            "  Building wheel for pyldavis (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyldavis: filename=pyLDAvis-3.3.1-py2.py3-none-any.whl size=136898 sha256=3f0218f96a740e15116e7150286c194498073878271b488c89b1ec4b614786e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/21/f6/17bcf2667e8a68532ba2fbf6d5c72fdf4c7f7d9abfa4852d2f\n",
            "Successfully built pyldavis\n",
            "Installing collected packages: funcy, pyldavis\n",
            "Successfully installed funcy-1.17 pyldavis-3.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.1.72-py2.py3-none-any.whl (8.3 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting anyascii\n",
            "  Downloading anyascii-0.3.1-py3-none-any.whl (287 kB)\n",
            "\u001b[K     |████████████████████████████████| 287 kB 7.4 MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 54.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.1 contractions-0.1.72 pyahocorasick-1.4.4 textsearch-0.0.21\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.1.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.0)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.17)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (57.4.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (4.2.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.3.5)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.8.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyLDAvis) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (6.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyLDAvis) (2.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from numexpr->pyLDAvis) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->numexpr->pyLDAvis) (3.0.9)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyLDAvis) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade gensim\n",
        "!pip install pyldavis\n",
        "! pip install bs4\n",
        "! pip install contractions\n",
        "!pip install pyLDAvis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tJKaDvCtA6N",
        "outputId": "2903fb26-0b95-4232-b059-e6dd5db6e056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import json\n",
        "import gzip\n",
        "import gensim\n",
        "import datetime\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# import pyLDAvis.gensim_models\n",
        "# import pickle \n",
        "# import pyLDAvis\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "from pprint import pprint\n",
        "from gensim import corpora\n",
        "from bs4 import BeautifulSoup\n",
        "from gensim.models.ldamodel import LdaModel\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "#import logging\n",
        "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {
        "id": "XaFV0a6dSL0x"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  dftweets = pd.read_csv('/content/drive/My Drive/Colab Notebooks/TCC/csv/pre_processed_tweets.csv', lineterminator='\\n', index_col=0)\n",
        "except:\n",
        "  print(\"Não foi possível carregar o arquivo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "AOpf51-c_IoG",
        "outputId": "ce54c55e-7550-4f11-9c5e-90c26e75cd22"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ba416bb8-ab94-49d5-9591-8c654a77adbe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>text</th>\n",
              "      <th>count_word</th>\n",
              "      <th>text_preprocessed</th>\n",
              "      <th>bigrams_text</th>\n",
              "      <th>text_lematizados</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-05-30 23:00:53+00:00</td>\n",
              "      <td>1531410348141592577</td>\n",
              "      <td>1473798922472767488</td>\n",
              "      <td>@BetoLuiz_RU @jonesmanoel_PCB @deccache O Hait...</td>\n",
              "      <td>15</td>\n",
              "      <td>haiti desgraca fato erros anulam acertos fala ...</td>\n",
              "      <td>haiti desgraca fato erros anulam acertos fala ...</td>\n",
              "      <td>haiti desgraca fato erro anular acerto falir s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-05-30 22:57:20+00:00</td>\n",
              "      <td>1531409451122577410</td>\n",
              "      <td>1521912766151417856</td>\n",
              "      <td>O senhor vai investir na educação da Venezuela...</td>\n",
              "      <td>15</td>\n",
              "      <td>senhor vai investir educacao venezuela argenti...</td>\n",
              "      <td>senhor vai investir_educacao venezuela argenti...</td>\n",
              "      <td>senhor ir investir_educacao venezuela argentin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-05-30 22:55:14+00:00</td>\n",
              "      <td>1531408925945434112</td>\n",
              "      <td>1253882714723409920</td>\n",
              "      <td>@rsallesmma Que nada, na mão de vocês já tá vi...</td>\n",
              "      <td>7</td>\n",
              "      <td>nada mao voces virando mistura deserto saara h...</td>\n",
              "      <td>nada mao voces virando mistura deserto_saara h...</td>\n",
              "      <td>nado mao voces virar misturar deserto_saara haiti</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-05-30 22:55:14+00:00</td>\n",
              "      <td>1531408923277807617</td>\n",
              "      <td>40320768</td>\n",
              "      <td>@JoppertLeonardo @jonesmanoel_PCB @deccache En...</td>\n",
              "      <td>21</td>\n",
              "      <td>entramos brics invadimos haiti mando bush lula...</td>\n",
              "      <td>entramos brics invadimos haiti mando_bush lula...</td>\n",
              "      <td>entrar brics invadir haiti mando_bush lula diz...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2022-05-30 22:37:49+00:00</td>\n",
              "      <td>1531404543568781313</td>\n",
              "      <td>1082697350441824257</td>\n",
              "      <td>@alice_mader9 kkkkkk e era 2 haitiano, n enten...</td>\n",
              "      <td>3</td>\n",
              "      <td>haitiano entendi nada falavam</td>\n",
              "      <td>haitiano entendi_nada falavam</td>\n",
              "      <td>haitiano entendi_nada falar</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba416bb8-ab94-49d5-9591-8c654a77adbe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ba416bb8-ab94-49d5-9591-8c654a77adbe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ba416bb8-ab94-49d5-9591-8c654a77adbe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                    datetime             tweet_id              user_id  \\\n",
              "1  2022-05-30 23:00:53+00:00  1531410348141592577  1473798922472767488   \n",
              "2  2022-05-30 22:57:20+00:00  1531409451122577410  1521912766151417856   \n",
              "3  2022-05-30 22:55:14+00:00  1531408925945434112  1253882714723409920   \n",
              "4  2022-05-30 22:55:14+00:00  1531408923277807617             40320768   \n",
              "5  2022-05-30 22:37:49+00:00  1531404543568781313  1082697350441824257   \n",
              "\n",
              "                                                text  count_word  \\\n",
              "1  @BetoLuiz_RU @jonesmanoel_PCB @deccache O Hait...          15   \n",
              "2  O senhor vai investir na educação da Venezuela...          15   \n",
              "3  @rsallesmma Que nada, na mão de vocês já tá vi...           7   \n",
              "4  @JoppertLeonardo @jonesmanoel_PCB @deccache En...          21   \n",
              "5  @alice_mader9 kkkkkk e era 2 haitiano, n enten...           3   \n",
              "\n",
              "                                   text_preprocessed  \\\n",
              "1  haiti desgraca fato erros anulam acertos fala ...   \n",
              "2  senhor vai investir educacao venezuela argenti...   \n",
              "3  nada mao voces virando mistura deserto saara h...   \n",
              "4  entramos brics invadimos haiti mando bush lula...   \n",
              "5                      haitiano entendi nada falavam   \n",
              "\n",
              "                                        bigrams_text  \\\n",
              "1  haiti desgraca fato erros anulam acertos fala ...   \n",
              "2  senhor vai investir_educacao venezuela argenti...   \n",
              "3  nada mao voces virando mistura deserto_saara h...   \n",
              "4  entramos brics invadimos haiti mando_bush lula...   \n",
              "5                      haitiano entendi_nada falavam   \n",
              "\n",
              "                                    text_lematizados  \n",
              "1  haiti desgraca fato erro anular acerto falir s...  \n",
              "2  senhor ir investir_educacao venezuela argentin...  \n",
              "3  nado mao voces virar misturar deserto_saara haiti  \n",
              "4  entrar brics invadir haiti mando_bush lula diz...  \n",
              "5                        haitiano entendi_nada falar  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dftweets.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXSlrhu_ipcL",
        "outputId": "3c609854-1ccc-454f-e2fd-8293c5b8d16a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['haiti desgraca fato erros anulam acertos fala sobre guerra_ucrania vem posicionando bem criticando postura zelensky',\n",
              " 'senhor vai investir_educacao venezuela argentina haiti cuba etc paises_comunistas porque aqui brasil senhor nunca fez',\n",
              " 'nada mao voces virando mistura deserto_saara haiti',\n",
              " 'entramos brics invadimos haiti mando_bush lula diz vai fortalecer brics faz palestras parlamento europeu esta tratando russia_china inimigos mortais vai funcionar',\n",
              " 'haitiano entendi_nada falavam']"
            ]
          },
          "metadata": {},
          "execution_count": 249
        }
      ],
      "source": [
        "dftweets.bigrams_text.head().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dftweets['datetime'] = pd.to_datetime(dftweets.datetime, format='%Y-%m-%d')"
      ],
      "metadata": {
        "id": "NJvYEJi8W0LY"
      },
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Agrupamento mensal"
      ],
      "metadata": {
        "id": "atK5iGuyW99J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {
        "id": "rvlaX6HQ_cpc"
      },
      "outputs": [],
      "source": [
        "#agrupar df por mês e adicionar os períodos numa lista\n",
        "mensal = [df_year_month for df_year_month in dftweets.groupby(pd.Grouper(key='datetime', freq='M', closed='left'))]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Agrupamento trimestral"
      ],
      "metadata": {
        "id": "8kRSd4LKWuWg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {
        "id": "mag8EwUwJy8Z"
      },
      "outputs": [],
      "source": [
        "trimestral = [df_year_3month for df_year_3month in dftweets.groupby(pd.Grouper(key='datetime', freq='3M', closed='left'))]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Definir como vai ser a repartição (mensal ou trimestral)"
      ],
      "metadata": {
        "id": "LpW0GqFGDwER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trim = True"
      ],
      "metadata": {
        "id": "_3suY6POFOfy"
      },
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = trimestral if trim else mensal"
      ],
      "metadata": {
        "id": "x5RhdxviC7Br"
      },
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {
        "id": "zAMSzBhBLVl4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dccdeb6-fc81-4fd1-a6be-0ad32442ef51"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 255
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_start_date = '01/01/2018'\n",
        "df_end_date = '31/05/2022'"
      ],
      "metadata": {
        "id": "krvhAEGZ3wla"
      },
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "id": "Q7tQ2hUlu8Eg"
      },
      "outputs": [],
      "source": [
        " #idenficar o período dos tweets\n",
        "def get_tweets_period(idx, df):\n",
        "\n",
        "  date_format = '%d/%m/%Y'\n",
        "  if idx == 0:\n",
        "    start_period = df_start_date\n",
        "    end_period = df[idx][0].strftime(date_format)\n",
        "  elif idx == len(df) - 1:\n",
        "    current_start_period = df[idx-1][0].strftime(date_format)\n",
        "    start_period = (datetime.datetime.strptime(current_start_period, date_format) + datetime.timedelta(days=1)).strftime(date_format)\n",
        "    end_period = df_end_date\n",
        "  else:\n",
        "    current_start_period = df[idx-1][0].strftime(date_format)\n",
        "    start_period = (datetime.datetime.strptime(current_start_period, date_format) + datetime.timedelta(days=1)).strftime(date_format)\n",
        "\n",
        "    end_period = df[idx][0].strftime(date_format)\n",
        "  return (start_period, end_period)   "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Listando os períodos"
      ],
      "metadata": {
        "id": "j7PX7BALCNSi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "id": "M5OTgA1RLFXZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23a60465-e09e-47e3-8d81-483129402f2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perído de [01/01/2018 a 31/03/2018]\n",
            "Perído de [01/04/2018 a 30/06/2018]\n",
            "Perído de [01/07/2018 a 30/09/2018]\n",
            "Perído de [01/10/2018 a 31/12/2018]\n",
            "Perído de [01/01/2019 a 31/03/2019]\n",
            "Perído de [01/04/2019 a 30/06/2019]\n",
            "Perído de [01/07/2019 a 30/09/2019]\n",
            "Perído de [01/10/2019 a 31/12/2019]\n",
            "Perído de [01/01/2020 a 31/03/2020]\n",
            "Perído de [01/04/2020 a 30/06/2020]\n",
            "Perído de [01/07/2020 a 30/09/2020]\n",
            "Perído de [01/10/2020 a 31/12/2020]\n",
            "Perído de [01/01/2021 a 31/03/2021]\n",
            "Perído de [01/04/2021 a 30/06/2021]\n",
            "Perído de [01/07/2021 a 30/09/2021]\n",
            "Perído de [01/10/2021 a 31/12/2021]\n",
            "Perído de [01/01/2022 a 31/03/2022]\n",
            "Perído de [01/04/2022 a 31/05/2022]\n"
          ]
        }
      ],
      "source": [
        "for idx, df_y_m in enumerate(df):\n",
        " start_period, end_period = get_tweets_period(idx, df)\n",
        " print(f'Perído de [{start_period} a {end_period}]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAq9vtux74XG"
      },
      "source": [
        "###gensim oficial doc \n",
        "https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html#sphx-glr-auto-examples-tutorials-run-lda-py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "id": "-5WEkWwF5D-f"
      },
      "outputs": [],
      "source": [
        "k_topicos = [3, 5, 7, 10, 15, 25]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "id": "Xs9R7fBRuJBh"
      },
      "outputs": [],
      "source": [
        "no_above_dict = 0.5\n",
        "dictionary_percent = 0.025\n",
        "iterations = 1000\n",
        "passes = 50\n",
        "random_state = 50\n",
        "   \n",
        "#palavras que não são significativas\n",
        "stop_words = ['nao','para','pra','aqui','trump', 'ir', 'ter', 'esse', 'todo','tudo', 'este', 'ser', 'querer', 'sao', 'pai', 'pro', 'ver', 'voce'] # 'fazer', 'dizer', 'falar'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HB6tn9zS0K0B"
      },
      "source": [
        "###Procurar e salvar o melhor número de tópicos (k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g67roHYnruYI",
        "outputId": "3753e198-6f07-4a0c-f90a-697a77771017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Período de [01/01/2018 a 31/03/2018]\n",
            "Tamanho do documento: 4796 tweets, 56126 palavras e 11.7 de médias de palavras\n",
            "--------------------------------------------------------------------------------\n",
            "Período de [01/04/2018 a 30/06/2018]\n",
            "Tamanho do documento: 4443 tweets, 52714 palavras e 11.86 de médias de palavras\n",
            "--------------------------------------------------------------------------------\n",
            "Período de [01/07/2018 a 30/09/2018]\n",
            "Tamanho do documento: 4574 tweets, 54364 palavras e 11.89 de médias de palavras\n",
            "--------------------------------------------------------------------------------\n",
            "Período de [01/10/2018 a 31/12/2018]\n",
            "Tamanho do documento: 4349 tweets, 55752 palavras e 12.82 de médias de palavras\n",
            "--------------------------------------------------------------------------------\n",
            "Período de [01/01/2019 a 31/03/2019]\n",
            "Tamanho do documento: 7341 tweets, 97960 palavras e 13.34 de médias de palavras\n",
            "--------------------------------------------------------------------------------\n",
            "Período de [01/04/2019 a 30/06/2019]\n",
            "Tamanho do documento: 5431 tweets, 71101 palavras e 13.09 de médias de palavras\n",
            "--------------------------------------------------------------------------------\n",
            "Período de [01/07/2019 a 30/09/2019]\n",
            "Tamanho do documento: 5620 tweets, 72527 palavras e 12.91 de médias de palavras\n",
            "--------------------------------------------------------------------------------\n",
            "Período de [01/10/2019 a 31/12/2019]\n",
            "Tamanho do documento: 6059 tweets, 79532 palavras e 13.13 de médias de palavras\n",
            "--------------------------------------------------------------------------------\n",
            "Período de [01/01/2020 a 31/03/2020]\n",
            "Tamanho do documento: 24600 tweets, 283533 palavras e 11.53 de médias de palavras\n",
            "--------------------------------------------------------------------------------\n",
            "Período de [01/04/2020 a 30/06/2020]\n",
            "Tamanho do documento: 11099 tweets, 135974 palavras e 12.25 de médias de palavras\n",
            "--------------------------------------------------------------------------------\n",
            "Período de [01/07/2020 a 30/09/2020]\n",
            "Tamanho do documento: 6610 tweets, 89064 palavras e 13.47 de médias de palavras\n",
            "--------------------------------------------------------------------------------\n",
            "Período de [01/10/2020 a 31/12/2020]\n",
            "Tamanho do documento: 5200 tweets, 68211 palavras e 13.12 de médias de palavras\n",
            "--------------------------------------------------------------------------------\n",
            "Período de [01/01/2021 a 31/03/2021]\n",
            "Tamanho do documento: 7155 tweets, 93466 palavras e 13.06 de médias de palavras\n",
            "--------------------------------------------------------------------------------\n",
            "Período de [01/04/2021 a 30/06/2021]\n",
            "Tamanho do documento: 7035 tweets, 89813 palavras e 12.77 de médias de palavras\n",
            "--------------------------------------------------------------------------------\n",
            "Período de [01/07/2021 a 30/09/2021]\n",
            "Tamanho do documento: 27699 tweets, 338706 palavras e 12.23 de médias de palavras\n",
            "--------------------------------------------------------------------------------\n",
            "Período de [01/10/2021 a 31/12/2021]\n",
            "Tamanho do documento: 6840 tweets, 88591 palavras e 12.95 de médias de palavras\n",
            "--------------------------------------------------------------------------------\n",
            "Período de [01/01/2022 a 31/03/2022]\n",
            "Tamanho do documento: 6878 tweets, 90712 palavras e 13.19 de médias de palavras\n",
            "--------------------------------------------------------------------------------\n",
            "Período de [01/04/2022 a 31/05/2022]\n",
            "Tamanho do documento: 4535 tweets, 60868 palavras e 13.42 de médias de palavras\n",
            "--------------------------------------------------------------------------------\n",
            "[3, 3, 5, 5, 5, 5, 5, 5, 25, 7, 3, 5, 3, 5, 5, 7, 5, 3]\n",
            "Best k solution is: 5\n"
          ]
        }
      ],
      "source": [
        "#best k topic of all\n",
        "best_k_topic_of_each = []\n",
        "lda_model = None\n",
        "for idx, mini_df in enumerate(df):\n",
        "  #df period and mini stats\n",
        "  start_period, end_period = get_tweets_period(idx, df)\n",
        "  print(f'Período de [{start_period} a {end_period}]')\n",
        "\n",
        "  words_count = mini_df[1]['count_word'].sum()\n",
        "  docs = mini_df[1].text_lematizados.tolist()\n",
        "  tam_doc = len(docs)\n",
        "\n",
        "  print(f'Tamanho do documento: {tam_doc} tweets, {words_count} palavras e {round(words_count/tam_doc, 2)} de médias de palavras')\n",
        "  print('-'*80)\n",
        " \n",
        "  texts = [[word for word in doc.split() if word not in stop_words and len(word) > 1] for doc in docs]\n",
        " \n",
        "  #texts = docs_list[0:3]\n",
        "\n",
        "  #criando o dicionário da representação dos documentos\n",
        "  dictionary = corpora.Dictionary(texts)\n",
        "\n",
        "  #Filtre as palavras que ocorrem em menos de 20 documentos ou em mais de 50% dos documentos.\n",
        "  dictionary.filter_extremes(no_below=int(tam_doc * dictionary_percent), no_above=no_above_dict)\n",
        "\n",
        "  #criando o corpus (bags-of-words dos documentos)\n",
        "  corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "\n",
        "  # print(texts[0])\n",
        "  # print(corpus[0])\n",
        "\n",
        "  # print(f'Number of unique tokens: {len(dictionary)}')\n",
        "  # print(f'Number of documents: {len(corpus)}')\n",
        "\n",
        "  dic_best = {\"c_v\": 0,\"k\": k_topicos[0], 'top_topics': []}\n",
        " \n",
        "  for i, k in enumerate(k_topicos):\n",
        "    lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=k, chunksize=tam_doc, \n",
        "                         alpha='auto', eta='auto', iterations=iterations, random_state=random_state, passes=passes, eval_every=None)\n",
        "    top_topics = lda_model.top_topics(corpus)\n",
        "\n",
        "    # Compute Coherence Score\n",
        "    coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "    coherence_lda = round(coherence_model_lda.get_coherence(), 4)\n",
        "    # print('Coherence Score: ', coherence_lda)\n",
        "    # print(f'Para {k} tópicos -------------{coherence_lda}')\n",
        "\n",
        "    if coherence_lda > dic_best[\"c_v\"]:\n",
        "      dic_best.update({'c_v': coherence_lda, 'k': k, 'top_topics': top_topics})\n",
        "     \n",
        "\n",
        "    # lda_model.save(f\"/content/drive/My Drive/Colab Notebooks/TCC/lda_data_by_period/period_{period}_k_topic_{k}\")\n",
        "    # lda_model.save(f\"/content/drive/My Drive/Colab Notebooks/TCC/lda_data_by_period/period_{period}_k_topic_{k}.bin\")\n",
        "    #pprint(top_topics)\n",
        "   \n",
        "    # for i, topic in enumerate(top_topics):\n",
        "    #   topic_list = [word[1] for word in topic[0]]\n",
        "    #   print(f'{i} : {topic_list}')\n",
        "    \n",
        "    # print('*'*200)\n",
        "    # print()\n",
        "  #adicionando o melhor k tópicos de cada corpus numa lista\n",
        "  best_k_topic_of_each.append(dic_best[\"k\"])  \n",
        "  #break\n",
        "\n",
        "print(best_k_topic_of_each)\n",
        "best_of_all = max(best_k_topic_of_each,key=best_k_topic_of_each.count)\n",
        "print(f'Best k solution is: {best_of_all}')\n",
        "\n",
        "#salvando o melhor tópico\n",
        "if trim:\n",
        "   lda_model.save(f\"/content/drive/My Drive/Colab Notebooks/TCC/k_topics_lda/{best_of_all}_trimestral\")\n",
        "   lda_model.save(f\"/content/drive/My Drive/Colab Notebooks/TCC/k_topics_lda/{best_of_all}_trimestral.bin\")\n",
        "else: \n",
        "   lda_model.save(f\"/content/drive/My Drive/Colab Notebooks/TCC/k_topics_lda/{best_of_all}\")\n",
        "   lda_model.save(f\"/content/drive/My Drive/Colab Notebooks/TCC/k_topics_lda/{best_of_all}topic.bin\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Salvando os tópicos do melhor K tópicos de todos os períodos"
      ],
      "metadata": {
        "id": "54Hg1E9clAHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 5 #atribuição manual conforme o resultado acima"
      ],
      "metadata": {
        "id": "iIhX6EKPx9Dw"
      },
      "execution_count": 332,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xBj5IquJRX5",
        "outputId": "685a2f47-68a6-49cc-d7da-8fd4710efa1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O melhor número de tópicos é: 5\n",
            "\n",
            "Período de [01/01/2018 a 31/03/2018]\n",
            "Período de [01/04/2018 a 30/06/2018]\n",
            "Período de [01/07/2018 a 30/09/2018]\n",
            "Período de [01/10/2018 a 31/12/2018]\n",
            "Período de [01/01/2019 a 31/03/2019]\n",
            "Período de [01/04/2019 a 30/06/2019]\n",
            "Período de [01/07/2019 a 30/09/2019]\n",
            "Período de [01/10/2019 a 31/12/2019]\n",
            "Período de [01/01/2020 a 31/03/2020]\n",
            "Período de [01/04/2020 a 30/06/2020]\n",
            "Período de [01/07/2020 a 30/09/2020]\n",
            "Período de [01/10/2020 a 31/12/2020]\n",
            "Período de [01/01/2021 a 31/03/2021]\n",
            "Período de [01/04/2021 a 30/06/2021]\n",
            "Período de [01/07/2021 a 30/09/2021]\n",
            "Período de [01/10/2021 a 31/12/2021]\n",
            "Período de [01/01/2022 a 31/03/2022]\n",
            "Período de [01/04/2022 a 31/05/2022]\n",
            "Tópicos salvos com sucesso!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "try:\n",
        "  if trim:\n",
        "      LdaModel.load(f\"/content/drive/My Drive/Colab Notebooks/TCC/k_topics_lda/{k}_trimestral.bin\")\n",
        "  else:\n",
        "      LdaModel.load(f\"/content/drive/My Drive/Colab Notebooks/TCC/k_topics_lda/{k}topic.bin\")\n",
        "      \n",
        "  print(f'O melhor número de tópicos é: {k}')\n",
        "  print()\n",
        "\n",
        "  for idx, mini_df in enumerate(df):\n",
        "\n",
        "    #df period and mini stats\n",
        "    start_period, end_period = get_tweets_period(idx, df)\n",
        "    print(f'Período de [{start_period} a {end_period}]')\n",
        "\n",
        "    docs = mini_df[1].text_lematizados.tolist()\n",
        "    tam_doc = len(docs)\n",
        "\n",
        "    texts = [[word for word in doc.split() if word not in stop_words and len(word) > 1] for doc in docs]\n",
        "\n",
        "    #criando o dicionário da representação dos documentos\n",
        "    dictionary = corpora.Dictionary(texts)\n",
        "    #Filtre as palavras que ocorrem em menos de 20 documentos ou em mais de 50% dos documentos.\n",
        "    dictionary.filter_extremes(no_below=int(tam_doc * dictionary_percent), no_above=no_above_dict)\n",
        "    #criando o corpus (bags-of-words dos documentos)\n",
        "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "\n",
        "    newLdaModel = LdaModel(corpus=corpus, id2word=dictionary, num_topics=k, chunksize=tam_doc, \n",
        "                        alpha='auto', eta='auto', iterations=iterations, random_state=random_state, passes=passes, eval_every=None)\n",
        "    \n",
        "    period = str(start_period+'_'+end_period).replace('/','_')\n",
        "\n",
        "    try:\n",
        "      if trim:\n",
        "        newLdaModel.save(f\"/content/drive/My Drive/Colab Notebooks/TCC/lda_data_by_period/period_{period}_k_topic_{k}_trimestral\")\n",
        "        newLdaModel.save(f\"/content/drive/My Drive/Colab Notebooks/TCC/lda_data_by_period/period_{period}_k_topic_{k}_trimestral.bin\")\n",
        "      else:\n",
        "        newLdaModel.save(f\"/content/drive/My Drive/Colab Notebooks/TCC/lda_data_by_period/period_{period}_k_topic_{k}\")\n",
        "        newLdaModel.save(f\"/content/drive/My Drive/Colab Notebooks/TCC/lda_data_by_period/period_{period}_k_topic_{k}.bin\")\n",
        "    except Exception as e: \n",
        "      print(e) \n",
        "  \n",
        "  print('Tópicos salvos com sucesso!')\n",
        "except Exception as e: \n",
        "  print(e) "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Mostrando os tópicos de cada período"
      ],
      "metadata": {
        "id": "46IZeF5olSur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "invalid_print_chars = ['.','*','\"',',']"
      ],
      "metadata": {
        "id": "zAv85XHOBDyF"
      },
      "execution_count": 309,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 331,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvygV7PFgH05",
        "outputId": "6732e99e-85b1-42a7-cec4-8df9038b0182"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O melhor número de tópicos é: 5\n",
            "\n",
            "Período de [01/01/2018 a 31/03/2018]\n",
            "----------------------------------------\n",
            "0 : ['merda', 'paises', 'africa', 'presidente', 'eua', 'chamar', 'ainda', 'militar', 'achar', 'dizer', 'sobrar', 'brasil', 'falar', 'saber', 'caro', 'poder', 'agora', 'vir', 'rir', 'gente']\n",
            "1 : ['haitiano', 'rir', 'ano', 'atar', 'agora', 'hoje', 'achar', 'vir', 'ainda', 'dizer', 'ficar', 'caro', 'dar', 'sobrar', 'brasil', 'falar', 'gente', 'chamar', 'saber', 'exercitar']\n",
            "2 : ['dizer', 'poder', 'saber', 'caro', 'dar', 'vir', 'achar', 'africa', 'exercitar', 'ainda', 'falar', 'chamar', 'militar', 'brasileiro', 'rir', 'fazer', 'gente', 'ficar', 'agora', 'atar']\n",
            "3 : ['fazer', 'sobrar', 'falar', 'gente', 'ainda', 'agora', 'vir', 'ficar', 'hoje', 'militar', 'rir', 'saber', 'haitiano', 'exercitar', 'africa', 'achar', 'ano', 'dizer', 'atar', 'caro']\n",
            "4 : ['brasil', 'exercitar', 'ficar', 'onu', 'brasileiro', 'militar', 'ainda', 'agora', 'hoje', 'atar', 'ano', 'africa', 'chamar', 'rir', 'saber', 'eua', 'sobrar', 'poder', 'fazer', 'achar']\n",
            "****************************************************************************************************************************************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "Período de [01/04/2018 a 30/06/2018]\n",
            "----------------------------------------\n",
            "0 : ['fazer', 'poder', 'ano', 'atar', 'selecao', 'mundo', 'outro', 'agora', 'ainda', 'messi', 'ficar', 'argentino', 'vir', 'jogar', 'saber', 'falar', 'achar', 'venezuela', 'sobrar', 'dizer']\n",
            "1 : ['falar', 'dizer', 'ficar', 'dar', 'dia', 'bem', 'ainda', 'povo', 'hoje', 'caro', 'sobrar', 'haitiano', 'atar', 'falir', 'outro', 'saber', 'ajudar', 'venezuela', 'mundo', 'fazer']\n",
            "2 : ['haitiano', 'saber', 'caro', 'vir', 'achar', 'falir', 'sobrar', 'outro', 'mundo', 'brasileiro', 'atar', 'agora', 'hoje', 'falar', 'ficar', 'fazer', 'dizer', 'povo', 'dar', 'ainda']\n",
            "3 : ['brasil', 'brasileiro', 'ajudar', 'cubar', 'agora', 'venezuela', 'povo', 'mundo', 'outro', 'atar', 'selecao', 'bem', 'saber', 'vir', 'ano', 'hoje', 'fazer', 'achar', 'poder', 'ficar']\n",
            "4 : ['argentino', 'contra', 'jogar', 'copar', 'messi', 'hoje', 'venezuela', 'selecao', 'atar', 'mundo', 'sobrar', 'caro', 'bem', 'achar', 'agora', 'ficar', 'outro', 'saber', 'brasil', 'dizer']\n",
            "****************************************************************************************************************************************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "Período de [01/07/2018 a 30/09/2018]\n",
            "----------------------------------------\n",
            "0 : ['vir', 'atar', 'sobrar', 'dia', 'ano', 'chegar', 'brasil', 'ficar', 'venezuela', 'hoje', 'haitiano', 'dizer', 'outro', 'caro', 'achar', 'agora', 'trabalhar', 'poder', 'falar', 'gente']\n",
            "1 : ['brasil', 'caro', 'dizer', 'gente', 'brasileiro', 'achar', 'outro', 'venezuela', 'fazer', 'dia', 'haitiano', 'agora', 'hoje', 'ficar', 'vir', 'bem', 'falar', 'dar', 'atar', 'trabalhar']\n",
            "2 : ['haitiano', 'bem', 'ficar', 'caro', 'gente', 'brasileiro', 'brasil', 'hoje', 'dizer', 'venezuela', 'achar', 'dia', 'dar', 'trabalhar', 'falar', 'chegar', 'atar', 'ano', 'outro', 'saber']\n",
            "3 : ['onu', 'saber', 'dar', 'agora', 'ficar', 'venezuela', 'dizer', 'brasil', 'achar', 'brasileiro', 'vir', 'poder', 'fazer', 'falar', 'ano', 'caro', 'gente', 'hoje', 'sobrar', 'haitiano']\n",
            "4 : ['fazer', 'falar', 'hoje', 'poder', 'trabalhar', 'ficar', 'haitiano', 'ano', 'venezuela', 'dia', 'caro', 'brasil', 'atar', 'outro', 'achar', 'gente', 'saber', 'dizer', 'sobrar', 'bem']\n",
            "****************************************************************************************************************************************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "Período de [01/10/2018 a 31/12/2018]\n",
            "----------------------------------------\n",
            "0 : ['haitiano', 'ajudar', 'caro', 'passar', 'ficar', 'trabalhar', 'achar', 'brasileiro', 'ainda', 'falar', 'fazer', 'agora', 'ano', 'sobrar', 'dizer', 'vir', 'povo', 'dar', 'hoje', 'saber']\n",
            "1 : ['cubar', 'brasileiro', 'outro', 'saber', 'paises', 'vir', 'congo', 'achar', 'ficar', 'militar', 'falar', 'brasil', 'venezuela', 'agora', 'governar', 'trabalhar', 'povo', 'sobrar', 'tambem', 'dizer']\n",
            "2 : ['brasil', 'venezuela', 'poder', 'tambem', 'achar', 'povo', 'agora', 'militar', 'caro', 'vir', 'trabalhar', 'bolsonaro', 'ano', 'fazer', 'passar', 'haitiano', 'saber', 'brasileiro', 'onu', 'cubar']\n",
            "3 : ['fazer', 'falar', 'ano', 'dar', 'bolsonaro', 'gente', 'ficar', 'trabalhar', 'saber', 'sobrar', 'caro', 'achar', 'agora', 'poder', 'militar', 'passar', 'vir', 'povo', 'onu', 'haitiano']\n",
            "4 : ['dizer', 'onu', 'atar', 'hoje', 'governar', 'ainda', 'sobrar', 'congo', 'passar', 'militar', 'caro', 'brasileiro', 'tambem', 'dar', 'achar', 'fazer', 'vir', 'venezuela', 'povo', 'trabalhar']\n",
            "****************************************************************************************************************************************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "Período de [01/01/2019 a 31/03/2019]\n",
            "----------------------------------------\n",
            "0 : ['fazer', 'saber', 'poder', 'sobrar', 'tambem', 'vir', 'onu', 'bem', 'hoje', 'dizer', 'povo', 'venezuela', 'outro', 'atar', 'caro', 'agora', 'trabalhar', 'gente', 'ano', 'ajudar']\n",
            "1 : ['brasil', 'ajudar', 'ajuda_humanitaria', 'ano', 'eua', 'venezuela', 'atar', 'petroleo', 'mandar', 'povo', 'dar', 'fazer', 'onu', 'dizer', 'saber', 'achar', 'tambem', 'paises', 'agora', 'bem']\n",
            "2 : ['governar', 'ficar', 'brasileiro', 'militar', 'paises', 'ainda', 'dar', 'bem', 'venezuela', 'passar', 'atar', 'eua', 'ajudar', 'saber', 'brasil', 'dizer', 'poder', 'onu', 'mandar', 'trabalhar']\n",
            "3 : ['venezuela', 'petroleo', 'eua', 'porque', 'humanitaria', 'terremoto', 'agora', 'outro', 'mundo', 'passar', 'dizer', 'gente', 'mandar', 'bem', 'ajudar', 'tambem', 'ajuda_humanitaria', 'povo', 'achar', 'dar']\n",
            "4 : ['haitiano', 'falar', 'achar', 'caro', 'trabalhar', 'povo', 'dizer', 'hoje', 'dar', 'gente', 'bem', 'atar', 'saber', 'outro', 'tambem', 'ainda', 'fazer', 'ficar', 'eua', 'passar']\n",
            "****************************************************************************************************************************************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "Período de [01/04/2019 a 30/06/2019]\n",
            "----------------------------------------\n",
            "0 : ['general', 'venezuela', 'contra', 'outro', 'heleno', 'tambem', 'brasileiro', 'brasil', 'dizer', 'hoje', 'vir', 'fazer', 'achar', 'dar', 'porque', 'ficar', 'onu', 'saber', 'atar', 'agora']\n",
            "1 : ['sobrar', 'poder', 'ano', 'atar', 'vir', 'agora', 'ficar', 'saber', 'tambem', 'dizer', 'falar', 'brasileiro', 'brasil', 'porque', 'dar', 'general', 'onu', 'bem', 'pessoa', 'falir']\n",
            "2 : ['haitiano', 'brasil', 'falar', 'hoje', 'costa_rica', 'achar', 'brasileiro', 'ficar', 'dar', 'atar', 'porque', 'vir', 'bem', 'agora', 'tambem', 'caro', 'dizer', 'sobrar', 'fazer', 'saber']\n",
            "3 : ['fazer', 'dizer', 'saber', 'dar', 'onu', 'pessoa', 'porque', 'hoje', 'brasil', 'ficar', 'general', 'haitiano', 'ajudar', 'achar', 'poder', 'falar', 'caro', 'bem', 'vir', 'brasileiro']\n",
            "4 : ['caro', 'ajudar', 'gente', 'eua', 'falir', 'bem', 'tambem', 'porque', 'ficar', 'vir', 'falar', 'brasil', 'fazer', 'haitiano', 'pessoa', 'dizer', 'poder', 'venezuela', 'dar', 'hoje']\n",
            "****************************************************************************************************************************************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "Período de [01/07/2019 a 30/09/2019]\n",
            "----------------------------------------\n",
            "0 : ['fazer', 'vir', 'agora', 'eua', 'mexico', 'ficar', 'onde', 'hoje', 'achar', 'atar', 'brasil', 'outro', 'ano', 'haitiano', 'dizer', 'bem', 'ainda', 'brasileiro', 'caro', 'dar']\n",
            "1 : ['falar', 'caro', 'dar', 'ano', 'outro', 'onde', 'ainda', 'ficar', 'haitiano', 'franco', 'achar', 'fazer', 'sobrar', 'atar', 'hoje', 'dizer', 'poder', 'brasileiro', 'bem', 'vir']\n",
            "2 : ['sobrar', 'saber', 'passar', 'general', 'poder', 'bem', 'ficar', 'onde', 'franco', 'ainda', 'fazer', 'dizer', 'haitiano', 'atar', 'falar', 'mexico', 'dar', 'tambem', 'brasileiro', 'achar']\n",
            "3 : ['brasil', 'franco', 'contra', 'tambem', 'brasileiro', 'mexico', 'dizer', 'ainda', 'fazer', 'dar', 'eua', 'passar', 'sobrar', 'haitiano', 'onde', 'bem', 'atar', 'outro', 'hoje', 'ficar']\n",
            "4 : ['haitiano', 'dizer', 'hoje', 'achar', 'atar', 'mexico', 'brasileiro', 'ficar', 'bem', 'ainda', 'onde', 'fazer', 'outro', 'vir', 'caro', 'falar', 'dar', 'ano', 'sobrar', 'franco']\n",
            "****************************************************************************************************************************************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "Período de [01/10/2019 a 31/12/2019]\n",
            "----------------------------------------\n",
            "0 : ['falar', 'saber', 'onu', 'passar', 'ainda', 'hoje', 'dizer', 'mundo', 'gente', 'ficar', 'outro', 'achar', 'presidente', 'onde', 'brasil', 'poder', 'haitiano', 'dia', 'tambem', 'dar']\n",
            "1 : ['fazer', 'ano', 'general', 'vir', 'agora', 'dar', 'haitiano', 'sobrar', 'falar', 'dizer', 'ficar', 'hoje', 'atar', 'brasil', 'gente', 'tambem', 'caro', 'achar', 'mundo', 'poder']\n",
            "2 : ['haitiano', 'dizer', 'tambem', 'caro', 'poder', 'dia', 'dar', 'gente', 'achar', 'hoje', 'atar', 'povo', 'falar', 'passar', 'ficar', 'contra', 'onde', 'vir', 'mundo', 'fazer']\n",
            "3 : ['povo', 'hoje', 'ficar', 'contra', 'brasileiro', 'outro', 'onde', 'presidente', 'tambem', 'atar', 'equador', 'poder', 'fazer', 'onu', 'falar', 'haitiano', 'dizer', 'dar', 'dia', 'mundo']\n",
            "4 : ['brasil', 'sobrar', 'chile', 'atar', 'mundo', 'equador', 'gente', 'achar', 'tambem', 'poder', 'agora', 'falar', 'outro', 'fazer', 'saber', 'vir', 'dia', 'presidente', 'hoje', 'contra']\n",
            "****************************************************************************************************************************************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "Período de [01/01/2020 a 31/03/2020]\n",
            "----------------------------------------\n",
            "0 : ['presidente', 'bolsonaro', 'dizer', 'agora', 'brasil', 'saber', 'brasileiro', 'caro', 'vir', 'atar', 'falar', 'falir', 'povo', 'achar', 'haiti', 'bem', 'poder', 'dar', 'voltar', 'ficar']\n",
            "1 : ['fazer', 'brasileiro', 'dizer', 'mandar', 'dar', 'atar', 'brasil', 'vir', 'saber', 'haiti', 'falir', 'agora', 'povo', 'presidente', 'voltar', 'bolsonaro', 'caro', 'falar', 'ficar', 'bem']\n",
            "2 : ['haiti', 'brasil', 'vir', 'saber', 'falir', 'povo', 'agora', 'brasileiro', 'voltar', 'bem', 'falar', 'sobrar', 'achar', 'poder', 'atar', 'dizer', 'ficar', 'fazer', 'presidente', 'mandar']\n",
            "3 : ['caro', 'poder', 'ainda', 'ficar', 'sobrar', 'haiti', 'vir', 'achar', 'dizer', 'saber', 'dar', 'povo', 'atar', 'fazer', 'agora', 'brasil', 'falir', 'falar', 'presidente', 'mandar']\n",
            "4 : ['falar', 'voltar', 'achar', 'bem', 'acabar', 'saber', 'agora', 'brasileiro', 'brasil', 'haiti', 'presidente', 'dar', 'ficar', 'atar', 'vir', 'dizer', 'poder', 'bolsonaro', 'mandar', 'falir']\n",
            "****************************************************************************************************************************************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "Período de [01/04/2020 a 30/06/2020]\n",
            "----------------------------------------\n",
            "0 : ['brasil', 'achar', 'caro', 'agora', 'ainda', 'ficar', 'gente', 'hoje', 'lembrar', 'sobrar', 'dar', 'haitiano', 'saber', 'atar', 'vir', 'falar', 'general', 'acabar', 'governar', 'dizer']\n",
            "1 : ['dizer', 'acabar', 'dar', 'vir', 'sobrar', 'haitiano', 'hoje', 'presidente', 'bolsonaro', 'caro', 'saber', 'bem', 'gente', 'brasil', 'governar', 'ficar', 'lembrar', 'agora', 'atar', 'poder']\n",
            "2 : ['haitiano', 'presidente', 'bolsonaro', 'general', 'lembrar', 'gente', 'hoje', 'dizer', 'ficar', 'agora', 'falar', 'acabar', 'sobrar', 'brasil', 'dar', 'atar', 'caro', 'vir', 'fazer', 'ainda']\n",
            "3 : ['fazer', 'saber', 'poder', 'lembrar', 'sobrar', 'gente', 'hoje', 'haitiano', 'bolsonaro', 'agora', 'general', 'vir', 'presidente', 'brasil', 'caro', 'achar', 'governar', 'falar', 'dar', 'acabar']\n",
            "4 : ['falar', 'governar', 'atar', 'bem', 'heleno', 'sobrar', 'hoje', 'gente', 'haitiano', 'lembrar', 'ficar', 'caro', 'agora', 'achar', 'saber', 'fazer', 'general', 'presidente', 'dar', 'dizer']\n",
            "****************************************************************************************************************************************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "Período de [01/07/2020 a 30/09/2020]\n",
            "----------------------------------------\n",
            "0 : ['saber', 'ficar', 'vir', 'dar', 'cubar', 'falir', 'brasileiro', 'bem', 'passar', 'gente', 'haitiano', 'dizer', 'tambem', 'brasil', 'ano', 'ainda', 'hoje', 'falar', 'sobrar', 'caro']\n",
            "1 : ['fazer', 'hoje', 'gente', 'agora', 'falar', 'tambem', 'ano', 'caro', 'saber', 'haitiano', 'ainda', 'bem', 'revolucao', 'passar', 'revolucao_haitiana', 'vir', 'dar', 'outro', 'ficar', 'mundo']\n",
            "2 : ['haitiano', 'dizer', 'achar', 'tambem', 'ainda', 'caro', 'falar', 'bem', 'passar', 'outro', 'saber', 'ficar', 'gente', 'falir', 'mundo', 'atar', 'hoje', 'vir', 'dar', 'sobrar']\n",
            "3 : ['brasil', 'historiar', 'poder', 'revolucao', 'caro', 'outro', 'bem', 'tambem', 'falar', 'dizer', 'fazer', 'sobrar', 'haitiano', 'saber', 'dar', 'atar', 'brasileiro', 'revolucao_haitiana', 'passar', 'ano']\n",
            "4 : ['sobrar', 'revolucao_haitiana', 'atar', 'outro', 'ano', 'eua', 'mundo', 'general', 'falar', 'dizer', 'tambem', 'bem', 'ainda', 'passar', 'ficar', 'brasil', 'falir', 'revolucao', 'vir', 'historiar']\n",
            "****************************************************************************************************************************************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "Período de [01/10/2020 a 31/12/2020]\n",
            "----------------------------------------\n",
            "0 : ['caro', 'brasileiro', 'ainda', 'falir', 'passar', 'bom', 'gente', 'dizer', 'bem', 'dar', 'fazer', 'saber', 'haitiano', 'agora', 'poder', 'falar', 'sobrar', 'outro', 'ficar', 'vir']\n",
            "1 : ['fazer', 'achar', 'ficar', 'general', 'hoje', 'bom', 'saber', 'haitiano', 'caro', 'historiar', 'bem', 'outro', 'falar', 'dar', 'sobrar', 'tambem', 'dizer', 'atar', 'agora', 'brasileiro']\n",
            "2 : ['haitiano', 'dizer', 'saber', 'sobrar', 'falar', 'agora', 'historiar', 'caro', 'bem', 'vir', 'hoje', 'bom', 'poder', 'ficar', 'atar', 'ano', 'brasileiro', 'dar', 'fazer', 'falir']\n",
            "3 : ['atar', 'poder', 'vir', 'gente', 'dar', 'venezuela', 'falar', 'brasil', 'caro', 'achar', 'tambem', 'bom', 'haitiano', 'dizer', 'agora', 'hoje', 'saber', 'ficar', 'eua', 'fazer']\n",
            "4 : ['brasil', 'ano', 'tambem', 'outro', 'bem', 'eua', 'historiar', 'dizer', 'hoje', 'sobrar', 'dar', 'atar', 'haitiano', 'ficar', 'fazer', 'agora', 'brasileiro', 'venezuela', 'saber', 'falar']\n",
            "****************************************************************************************************************************************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "Período de [01/01/2021 a 31/03/2021]\n",
            "----------------------------------------\n",
            "0 : ['brasil', 'sobrar', 'ano', 'agora', 'poder', 'eua', 'estar', 'bolsonaro', 'atar', 'vir', 'ficar', 'dizer', 'hoje', 'haitiano', 'saber', 'governar', 'presidente', 'fazer', 'achar', 'tambem']\n",
            "1 : ['haitiano', 'presidente', 'dizer', 'atar', 'hoje', 'bolsonaro', 'achar', 'vir', 'estar', 'ano', 'falar', 'poder', 'ficar', 'fazer', 'dar', 'brasil', 'caro', 'povo', 'eua', 'agora']\n",
            "2 : ['fazer', 'governar', 'caro', 'ficar', 'ainda', 'outro', 'dizer', 'haitiano', 'ano', 'estar', 'bolsonaro', 'falar', 'gente', 'brasil', 'saber', 'eua', 'poder', 'atar', 'vir', 'achar']\n",
            "3 : ['brasileiro', 'dar', 'dia', 'tambem', 'haitiano', 'ano', 'fazer', 'poder', 'brasil', 'outro', 'povo', 'achar', 'estar', 'hoje', 'dizer', 'falar', 'agora', 'sobrar', 'atar', 'ainda']\n",
            "4 : ['falar', 'saber', 'povo', 'poder', 'gente', 'eua', 'estar', 'ficar', 'haitiano', 'bolsonaro', 'vir', 'fazer', 'dizer', 'outro', 'atar', 'presidente', 'achar', 'agora', 'ano', 'sobrar']\n",
            "****************************************************************************************************************************************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "Período de [01/04/2021 a 30/06/2021]\n",
            "----------------------------------------\n",
            "0 : ['falar', 'saber', 'ficar', 'poder', 'tambem', 'bem', 'sobrar', 'dar', 'gente', 'vir', 'ainda', 'brasil', 'haitiano', 'caro', 'atar', 'lembrar', 'ano', 'outro', 'dizer', 'agora']\n",
            "1 : ['haitiano', 'ainda', 'dar', 'lembrar', 'agora', 'falar', 'vir', 'achar', 'brasil', 'saber', 'atar', 'dizer', 'outro', 'caro', 'ficar', 'ano', 'gente', 'presidente', 'passar', 'bem']\n",
            "2 : ['brasil', 'caro', 'passar', 'contra', 'outro', 'gente', 'vir', 'ficar', 'haitiano', 'atar', 'falar', 'achar', 'bem', 'fazer', 'lembrar', 'poder', 'ainda', 'dar', 'saber', 'ano']\n",
            "3 : ['dizer', 'achar', 'presidente', 'bolsonaro', 'historiar', 'haitiano', 'brasil', 'sobrar', 'bem', 'falar', 'vir', 'gente', 'passar', 'saber', 'agora', 'lembrar', 'caro', 'tambem', 'ano', 'ainda']\n",
            "4 : ['fazer', 'atar', 'hoje', 'ano', 'sobrar', 'brasil', 'saber', 'haitiano', 'dar', 'achar', 'bem', 'caro', 'contra', 'ainda', 'agora', 'outro', 'poder', 'lembrar', 'vir', 'gente']\n",
            "****************************************************************************************************************************************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "Período de [01/07/2021 a 30/09/2021]\n",
            "----------------------------------------\n",
            "0 : ['presidente', 'fazer', 'falar', 'casar', 'brasil', 'sobrar', 'hoje', 'brasileiro', 'ainda', 'agora', 'outro', 'cubar', 'mundo', 'poder', 'atar', 'terremoto', 'saber', 'haitiano', 'governar', 'ajudar']\n",
            "1 : ['cubar', 'eua', 'dizer', 'assassinato_presidente', 'atar', 'brasil', 'fazer', 'saber', 'agora', 'poder', 'brasileiro', 'sobrar', 'haitiano', 'presidente', 'ainda', 'outro', 'mundo', 'governar', 'falar', 'ficar']\n",
            "2 : ['terremoto', 'povo', 'mundo', 'governar', 'brasileiro', 'ficar', 'brasil', 'agora', 'fazer', 'presidente', 'eua', 'afeganistao', 'saber', 'ainda', 'haitiano', 'outro', 'falar', 'atar', 'ajudar', 'poder']\n",
            "3 : ['sobrar', 'afeganistao', 'poder', 'ajudar', 'agora', 'hoje', 'brasil', 'ainda', 'mundo', 'saber', 'terremoto', 'governar', 'brasileiro', 'ficar', 'falar', 'fazer', 'tambem', 'cubar', 'eua', 'assassinato_presidente']\n",
            "4 : ['haitiano', 'brasil', 'saber', 'ainda', 'outro', 'tambem', 'povo', 'presidente', 'brasileiro', 'ajudar', 'eua', 'falar', 'fazer', 'governar', 'terremoto', 'cubar', 'afeganistao', 'agora', 'hoje', 'ficar']\n",
            "****************************************************************************************************************************************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "Período de [01/10/2021 a 31/12/2021]\n",
            "----------------------------------------\n",
            "0 : ['fazer', 'eua', 'ficar', 'achar', 'brasileiro', 'governar', 'poder', 'sobrar', 'caro', 'presidente', 'brasil', 'atar', 'paises', 'haitiano', 'povo', 'agora', 'outro', 'saber', 'dizer', 'tambem']\n",
            "1 : ['falar', 'sobrar', 'hoje', 'poder', 'outro', 'ainda', 'vir', 'saber', 'ficar', 'haitiano', 'brasil', 'passar', 'achar', 'venezuela', 'brasileiro', 'caro', 'pessoa', 'dizer', 'agora', 'paises']\n",
            "2 : ['dizer', 'ano', 'tambem', 'atar', 'povo', 'pessoa', 'ficar', 'venezuela', 'ainda', 'passar', 'haitiano', 'hoje', 'saber', 'outro', 'vir', 'poder', 'presidente', 'achar', 'brasileiro', 'brasil']\n",
            "3 : ['brasil', 'saber', 'paises', 'mundo', 'governar', 'venezuela', 'passar', 'agora', 'povo', 'tambem', 'ainda', 'pessoa', 'dizer', 'fazer', 'presidente', 'ficar', 'brasileiro', 'haitiano', 'hoje', 'atar']\n",
            "4 : ['haitiano', 'venezuela', 'caro', 'achar', 'agora', 'passar', 'brasileiro', 'presidente', 'ficar', 'poder', 'governar', 'vir', 'ainda', 'povo', 'saber', 'falar', 'brasil', 'pessoa', 'sobrar', 'dizer']\n",
            "****************************************************************************************************************************************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "Período de [01/01/2022 a 31/03/2022]\n",
            "----------------------------------------\n",
            "0 : ['falar', 'africa', 'cubar', 'gente', 'pessoa', 'mundo', 'venezuela', 'brasil', 'outro', 'assim', 'tambem', 'paises', 'eua', 'poder', 'atar', 'ficar', 'historiar', 'sobrar', 'achar', 'povo']\n",
            "1 : ['dizer', 'sobrar', 'guerra', 'ainda', 'agora', 'vir', 'ficar', 'mundo', 'brasil', 'pessoa', 'haitiano', 'bem', 'saber', 'fazer', 'dar', 'venezuela', 'ano', 'outro', 'falar', 'brasileiro']\n",
            "2 : ['fazer', 'eua', 'ano', 'venezuela', 'paises', 'poder', 'hoje', 'povo', 'brasil', 'mundo', 'atar', 'assim', 'ficar', 'agora', 'pessoa', 'tambem', 'cubar', 'guerra', 'outro', 'falar']\n",
            "3 : ['haitiano', 'caro', 'atar', 'tambem', 'historiar', 'bem', 'ficar', 'poder', 'dar', 'fazer', 'vir', 'saber', 'brasil', 'dizer', 'brasileiro', 'hoje', 'sobrar', 'achar', 'assim', 'ainda']\n",
            "4 : ['brasil', 'saber', 'achar', 'brasileiro', 'outro', 'mundo', 'dar', 'assim', 'ficar', 'poder', 'atar', 'pessoa', 'africa', 'haitiano', 'sobrar', 'bem', 'dizer', 'tambem', 'paises', 'venezuela']\n",
            "****************************************************************************************************************************************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "Período de [01/04/2022 a 31/05/2022]\n",
            "----------------------------------------\n",
            "0 : ['sobrar', 'onu', 'guerra', 'nunca', 'falar', 'bem', 'fazer', 'dizer', 'nado', 'haitiano', 'historiar', 'dar', 'tambem', 'contra', 'brasil', 'achar', 'paises', 'mundo', 'ficar', 'brasileiro']\n",
            "1 : ['falar', 'poder', 'eua', 'contra', 'ainda', 'agora', 'outro', 'ficar', 'caro', 'haitiano', 'dizer', 'fazer', 'nado', 'bem', 'tambem', 'historiar', 'paises', 'dar', 'atar', 'guerra']\n",
            "2 : ['brasil', 'venezuela', 'tambem', 'mal', 'bem', 'cubar', 'mundo', 'paises', 'fazer', 'ainda', 'achar', 'falar', 'atar', 'eua', 'agora', 'nado', 'dar', 'ficar', 'contra', 'brasileiro']\n",
            "3 : ['dizer', 'ano', 'brasileiro', 'dar', 'caro', 'hoje', 'paises', 'mundo', 'venezuela', 'achar', 'bem', 'outro', 'cubar', 'ficar', 'nado', 'ainda', 'atar', 'haitiano', 'saber', 'historiar']\n",
            "4 : ['haitiano', 'fazer', 'atar', 'saber', 'achar', 'historiar', 'nado', 'ficar', 'bem', 'brasileiro', 'brasil', 'dizer', 'falar', 'ainda', 'sobrar', 'mundo', 'cubar', 'ano', 'dar', 'paises']\n",
            "****************************************************************************************************************************************************************************************************************************\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "try:\n",
        "  # if trim:\n",
        "  #   LdaModel.load(f\"/content/drive/My Drive/Colab Notebooks/TCC/k_topics_lda/{k}_trimestral.bin\")\n",
        "  # else:\n",
        "  #   LdaModel.load(f\"/content/drive/My Drive/Colab Notebooks/TCC/k_topics_lda/{k}topic.bin\")\n",
        "\n",
        "  print(f'O melhor número de tópicos é: {k}')\n",
        "  print()\n",
        "\n",
        "  for idx, df_y_m in enumerate(df):\n",
        "    start_period, end_period = get_tweets_period(idx, df)\n",
        "    print(f'Período de [{start_period} a {end_period}]')\n",
        "    print('-'*40)\n",
        "\n",
        "    period = str(start_period+'_'+end_period).replace('/','_')\n",
        "\n",
        "    if trim:\n",
        "      LDA = LdaModel.load(f\"/content/drive/My Drive/Colab Notebooks/TCC/lda_data_by_period/period_{period}_k_topic_{k}_trimestral.bin\")\n",
        "    else:  \n",
        "      LDA = LdaModel.load(f\"/content/drive/My Drive/Colab Notebooks/TCC/lda_data_by_period/period_{period}_k_topic_{k}.bin\")\n",
        "\n",
        "    topics = LDA.show_topics(num_words=20)\n",
        "\n",
        "    #print(topics)\n",
        "    for i, top in enumerate(topics):\n",
        "      topic = (''.join([word.strip() for word in top[1] if not word.isdigit() and word not in invalid_print_chars])).split('+')\n",
        "      print(f'{i} : {topic}')\n",
        "\n",
        "    print('*'*220)\n",
        "    print('\\n\\n')\n",
        "except Exception as e:\n",
        "  print(e)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "LDA_with_gensim.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPY9Vea3rYHJl3rAGEfg6ok",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}